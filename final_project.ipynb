{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Markechy/Data-Science-Final-Project/blob/master/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70cb06b4-f58d-46e0-8f71-b616bcc0512d",
      "metadata": {
        "id": "70cb06b4-f58d-46e0-8f71-b616bcc0512d"
      },
      "source": [
        "# Final Project\n",
        "\n",
        "This final project can be collaborative. The maximum members of a group is 3. You can also work by yourself. Please respect the academic integrity. **Remember: if you get caught on cheating, you get F.**\n",
        "\n",
        "## A Introduction to the competition\n",
        "\n",
        "<img src=\"https://github.com/Markechy/Data-Science-Final-Project/blob/master/news-sexisme-EN.jpg?raw=1\" alt=\"drawing\" width=\"380\"/>\n",
        "\n",
        "Sexism is a growing problem online. It can inflict harm on women who are targeted, make online spaces inaccessible and unwelcoming, and perpetuate social asymmetries and injustices. Automated tools are now widely deployed to find, and assess sexist content at scale but most only give classifications for generic, high-level categories, with no further explanation. Flagging what is sexist content and also explaining why it is sexist improves interpretability, trust and understanding of the decisions that automated tools use, empowering both users and moderators.\n",
        "\n",
        "This project is based on SemEval 2023 - Task 10 - Explainable Detection of Online Sexism (EDOS). [Here](https://codalab.lisn.upsaclay.fr/competitions/7124#learn_the_details-overview) you can find a detailed introduction to this task.\n",
        "\n",
        "You only need to complete **TASK A - Binary Sexism Detection: a two-class (or binary) classification where systems have to predict whether a post is sexist or not sexist**. To cut down training time, we only use a subset of the original dataset (5k out of 20k). The dataset can be found in the same folder.\n",
        "\n",
        "Different from our previous homework, this competition gives you great flexibility (and very few hints). You can freely determine every component of your workflow, including but not limited to:\n",
        "-  **Preprocessing the input text**: You may decide how to clean or transform the text. For example, removing emojis or URLs, lowercasing, removing stopwords, applying stemming or lemmatization, correcting spelling, or performing tokenization and sentence segmentation.\n",
        "-  **Feature extraction and encoding**: You can choose any method to convert text into numerical representations, such as TF-IDF, Bag-of-Words, N-grams, Word2Vec, GloVe, FastText, contextual embeddings (e.g., BERT, RoBERTa, or other transformer-based models), Part-of-Speech (POS) tagging, dependency-based features, sentiment or emotion features, readability metrics, or even embeddings or features generated by large language models (LLMs).\n",
        "-  **Data augmentation and enrichment**: You may expand or balance your dataset by incorporating other related corpora or using techniques like synonym replacement, random deletion/insertion, or LLM-assisted augmentation (e.g., generating paraphrased or synthetic examples to improve model robustness).\n",
        "-  **Model selection**: You are free to experiment with different models ‚Äî from traditional machine learning algorithms (e.g., Logistic Regression, SVM, Random Forest, XGBoost) to deep learning architectures (e.g., CNNs, RNNs, Transformers), or even hybrid/ensemble approaches that combine multiple models or leverage LLM-generated predictions or reasoning.\n",
        "\n",
        "## Requirements\n",
        "-  **Input**: the text for each instance.\n",
        "-  **Output**: the binary label for each instance.\n",
        "-  **Feature engineering**: use at least 2 different methods to extract features and encode text into numerical values. You may explore both traditional and AI-assisted techniques. Data augmentation is optional.\n",
        "-  **Model selection**: implement with at least 3 different models and compare their performance.\n",
        "-  **Evaluation**: create a dataframe with rows indicating feature+model and columns indicating Precision (P), Recall (R) and F1-score (using weighted average). Your results should have at least 6 rows (2 feature engineering methods x 3 models). Report best performance with (1) your feature engineering method, and (2) the model you choose. Here is an example illustrating how the experimental results table should be presented.\n",
        "\n",
        "| Feature + Model | Sexist (P) | Sexist (R) | Sexist (F1) | Non-Sexist (P) | Non-Sexist (R) | Non-Sexist (F1) | Weighted (P) | Weighted (R) | Weighted (F1) |\n",
        "|-----------------|:----------:|:----------:|:------------:|:---------------:|:---------------:|:----------------:|:-------------:|:--------------:|:---------------:|\n",
        "| TF-IDF + Logistic Regression | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
        "\n",
        "- **Format of the report**: add explainations for each step (you can add markdown cells). At the end of the report, write a summary for each sections:\n",
        "    - Data Preprocessing\n",
        "    - Feature Engineering\n",
        "    - Model Selection and Architecture\n",
        "    - Training and Validation\n",
        "    - Evaluation and Results\n",
        "    - Use of Generative AI (if you use)\n",
        "\n",
        "## Rules\n",
        "Violations will result in 0 points in the grade:\n",
        "-   `Rule 1 - No test set leakage`: You must not use any instance from the test set during training, feature engineering, or model selection.\n",
        "-   `Rule 2 - Responsible AI use`: You may use generative AI, but you must clearly document how it was used. If you have used genAI, include a section titled ‚ÄúUse of Generative AI‚Äù describing:\n",
        "    -   What parts of the project you used AI for\n",
        "    -   What was implemented manually vs. with AI assistance\n",
        "\n",
        "## Grading\n",
        "\n",
        "The performance should be only evaluated on the test set (a total of 1086 instances). Please split original dataset into train set and test set. The test set should NEVER be used in the training process. The evaluation metric is a combination of precision, recall, and f1-score (use `classification_report` in sklearn).\n",
        "\n",
        "The total points are 10.0. Each team will compete with other teams in the class on their best performance. Points will be deducted if not following the requirements above.\n",
        "\n",
        "If ALL the requirements are met:\n",
        "- Top 25\\% teams: 10.0 points.\n",
        "- Top 25\\% - 50\\% teams: 8.5 points.\n",
        "- Top 50\\% - 75\\% teams: 7.0 points.\n",
        "- Top 75\\% - 100\\% teams: 6.0 points.\n",
        "\n",
        "If your best performance reaches **0.82** or above (weighted F1-score) and follows all the requirements and rules, you will also get full points (10.0 points).\n",
        "\n",
        "## Submission\n",
        "Similar as homework, submit both a PDF and .ipynb version of the report including:\n",
        "- code and experimental results with details explained\n",
        "- combined results table, report and best performance\n",
        "- a summary at the end of the report (please follow the format above)\n",
        "\n",
        "Missing any part of the above requirements will result in point deductions.\n",
        "\n",
        "The due date is **Dec 11, Thursday by 11:59pm**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6156cb23",
      "metadata": {
        "id": "6156cb23"
      },
      "outputs": [],
      "source": [
        "#Rena Wang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "13f3da4e",
      "metadata": {
        "id": "13f3da4e"
      },
      "outputs": [],
      "source": [
        "#Marco Antonio Gonzalez Fernandez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4feddf",
      "metadata": {
        "id": "7d4feddf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f8675e93",
      "metadata": {
        "id": "f8675e93"
      },
      "source": [
        "## Experimental Results\n",
        "\n",
        "(A table detailed model performance on the test set with at least 6 rows. Report the best performance.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72f84b04",
      "metadata": {
        "id": "72f84b04"
      },
      "source": [
        "## Project Summary\n",
        "### 1. Data Preprocessing\n",
        "\n",
        "\n",
        "### 2. Feature Engineering\n",
        "\n",
        "\n",
        "### 3. Model Selection and Architecture\n",
        "\n",
        "\n",
        "### 4. Training and Validation\n",
        "\n",
        "\n",
        "### 5. Evaluation and Results\n",
        "\n",
        "\n",
        "### 6. Use of Generative AI (if you use)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "242656d2",
      "metadata": {
        "id": "242656d2"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "68fb6514",
      "metadata": {
        "id": "68fb6514"
      },
      "source": [
        "# Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "002efa45",
      "metadata": {
        "id": "002efa45"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d042296",
      "metadata": {
        "id": "4d042296"
      },
      "source": [
        "# 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kxziJL4tHo39",
      "metadata": {
        "id": "kxziJL4tHo39"
      },
      "source": [
        "We first start by loading the data and clean up the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "15507281",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "15507281",
        "outputId": "a232a754-40f5-49ce-f42f-426d8e62c1eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rewire_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sexism2022_english-9609</td>\n",
              "      <td>In Nigeria, if you rape a woman, the men rape ...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sexism2022_english-16993</td>\n",
              "      <td>Then, she's a keeper. üòâ</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sexism2022_english-13149</td>\n",
              "      <td>This is like the Metallica video where the poo...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sexism2022_english-13021</td>\n",
              "      <td>woman?</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sexism2022_english-966</td>\n",
              "      <td>I bet she wished she had a gun</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5274</th>\n",
              "      <td>sexism2022_english-4599</td>\n",
              "      <td>Only if you make it clear you're not looking f...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5275</th>\n",
              "      <td>sexism2022_english-1196</td>\n",
              "      <td>It was like a big sisterhood all stemming from...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5276</th>\n",
              "      <td>sexism2022_english-9772</td>\n",
              "      <td>It goes like this: I'm on the dance floor and ...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5277</th>\n",
              "      <td>sexism2022_english-14511</td>\n",
              "      <td>It could be like for the ladies' corner of you...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5278</th>\n",
              "      <td>sexism2022_english-9538</td>\n",
              "      <td>Yea. Most trans women hate men.</td>\n",
              "      <td>sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5279 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     rewire_id  \\\n",
              "0      sexism2022_english-9609   \n",
              "1     sexism2022_english-16993   \n",
              "2     sexism2022_english-13149   \n",
              "3     sexism2022_english-13021   \n",
              "4       sexism2022_english-966   \n",
              "...                        ...   \n",
              "5274   sexism2022_english-4599   \n",
              "5275   sexism2022_english-1196   \n",
              "5276   sexism2022_english-9772   \n",
              "5277  sexism2022_english-14511   \n",
              "5278   sexism2022_english-9538   \n",
              "\n",
              "                                                   text       label  split  \n",
              "0     In Nigeria, if you rape a woman, the men rape ...  not sexist  train  \n",
              "1                               Then, she's a keeper. üòâ  not sexist  train  \n",
              "2     This is like the Metallica video where the poo...  not sexist  train  \n",
              "3                                                woman?  not sexist  train  \n",
              "4                        I bet she wished she had a gun  not sexist  train  \n",
              "...                                                 ...         ...    ...  \n",
              "5274  Only if you make it clear you're not looking f...  not sexist  train  \n",
              "5275  It was like a big sisterhood all stemming from...      sexist   test  \n",
              "5276  It goes like this: I'm on the dance floor and ...  not sexist   test  \n",
              "5277  It could be like for the ladies' corner of you...      sexist   test  \n",
              "5278                    Yea. Most trans women hate men.      sexist  train  \n",
              "\n",
              "[5279 rows x 4 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read de csv file and create a data frame\n",
        "edos_df = pd.read_csv(\"edos_labelled_data.csv\")\n",
        "edos_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "828001a4",
      "metadata": {
        "id": "828001a4"
      },
      "outputs": [],
      "source": [
        "#Function that help us to clean text\n",
        "\n",
        "def clean_text(line):\n",
        "    if pd.isna(line):\n",
        "        return line\n",
        "\n",
        "    #Lower case the text\n",
        "    line = line.lower()\n",
        "\n",
        "    #Remove URLs\n",
        "    line = re.sub(r'http\\S+|www.\\S+', '', line)\n",
        "\n",
        "    #Remove @mentions\n",
        "    line = re.sub(r'@\\w+', '', line)\n",
        "\n",
        "    #Remove [user] and [url]\n",
        "    line = re.sub(r'\\[user\\]', '', line)\n",
        "    line = re.sub(r'\\[url\\]', '', line)\n",
        "\n",
        "    #Remove multiple spaces\n",
        "    line = re.sub(r'\\s+', ' ', line).strip()\n",
        "\n",
        "    return line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dd1f8072",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dd1f8072",
        "outputId": "b1711152-93b1-4577-f13b-16a5106b5a10"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rewire_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sexism2022_english-9609</td>\n",
              "      <td>in nigeria, if you rape a woman, the men rape ...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sexism2022_english-16993</td>\n",
              "      <td>then, she's a keeper. üòâ</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sexism2022_english-13149</td>\n",
              "      <td>this is like the metallica video where the poo...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sexism2022_english-13021</td>\n",
              "      <td>woman?</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sexism2022_english-966</td>\n",
              "      <td>i bet she wished she had a gun</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5274</th>\n",
              "      <td>sexism2022_english-4599</td>\n",
              "      <td>only if you make it clear you're not looking f...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5275</th>\n",
              "      <td>sexism2022_english-1196</td>\n",
              "      <td>it was like a big sisterhood all stemming from...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5276</th>\n",
              "      <td>sexism2022_english-9772</td>\n",
              "      <td>it goes like this: i'm on the dance floor and ...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5277</th>\n",
              "      <td>sexism2022_english-14511</td>\n",
              "      <td>it could be like for the ladies' corner of you...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5278</th>\n",
              "      <td>sexism2022_english-9538</td>\n",
              "      <td>yea. most trans women hate men.</td>\n",
              "      <td>sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5279 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     rewire_id  \\\n",
              "0      sexism2022_english-9609   \n",
              "1     sexism2022_english-16993   \n",
              "2     sexism2022_english-13149   \n",
              "3     sexism2022_english-13021   \n",
              "4       sexism2022_english-966   \n",
              "...                        ...   \n",
              "5274   sexism2022_english-4599   \n",
              "5275   sexism2022_english-1196   \n",
              "5276   sexism2022_english-9772   \n",
              "5277  sexism2022_english-14511   \n",
              "5278   sexism2022_english-9538   \n",
              "\n",
              "                                                   text       label  split  \n",
              "0     in nigeria, if you rape a woman, the men rape ...  not sexist  train  \n",
              "1                               then, she's a keeper. üòâ  not sexist  train  \n",
              "2     this is like the metallica video where the poo...  not sexist  train  \n",
              "3                                                woman?  not sexist  train  \n",
              "4                        i bet she wished she had a gun  not sexist  train  \n",
              "...                                                 ...         ...    ...  \n",
              "5274  only if you make it clear you're not looking f...  not sexist  train  \n",
              "5275  it was like a big sisterhood all stemming from...      sexist   test  \n",
              "5276  it goes like this: i'm on the dance floor and ...  not sexist   test  \n",
              "5277  it could be like for the ladies' corner of you...      sexist   test  \n",
              "5278                    yea. most trans women hate men.      sexist  train  \n",
              "\n",
              "[5279 rows x 4 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Clean text column\n",
        "edos_df['text'] = edos_df['text'].apply(clean_text)\n",
        "edos_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x-cx6DoUHkiH",
      "metadata": {
        "id": "x-cx6DoUHkiH"
      },
      "source": [
        "The EDOS dataset already provides a predefined split for training and evaluation. Instead of randomly dividing the data ourselves, we follow the dataset‚Äôs built-in labels to ensure consistency with the competition setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f4bb516d",
      "metadata": {
        "id": "f4bb516d"
      },
      "outputs": [],
      "source": [
        "#Split original dataset into test set and train set\n",
        "test_df  = edos_df[edos_df['split'] == 'test'].copy()\n",
        "train_df = edos_df[edos_df['split'] == 'train'].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c9c49881",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "c9c49881",
        "outputId": "bf431662-69f1-4003-cf6c-8b0220f443ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rewire_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>sexism2022_english-845</td>\n",
              "      <td>fuck the niggers and the jews. both have a his...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>sexism2022_english-6629</td>\n",
              "      <td>well then good because someone has to knock he...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>sexism2022_english-17573</td>\n",
              "      <td>#usa #texas #islam #muslims #islamization #sha...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>sexism2022_english-10268</td>\n",
              "      <td>yes, normal women want to be dominated. social...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>sexism2022_english-10735</td>\n",
              "      <td>she didn't have to be a bitch about it. she li...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>sexism2022_english-19421</td>\n",
              "      <td>so did you break it off with her then.</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5270</th>\n",
              "      <td>sexism2022_english-15150</td>\n",
              "      <td>in early middle school i was physically bullie...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5275</th>\n",
              "      <td>sexism2022_english-1196</td>\n",
              "      <td>it was like a big sisterhood all stemming from...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5276</th>\n",
              "      <td>sexism2022_english-9772</td>\n",
              "      <td>it goes like this: i'm on the dance floor and ...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5277</th>\n",
              "      <td>sexism2022_english-14511</td>\n",
              "      <td>it could be like for the ladies' corner of you...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1086 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     rewire_id  \\\n",
              "21      sexism2022_english-845   \n",
              "27     sexism2022_english-6629   \n",
              "35    sexism2022_english-17573   \n",
              "38    sexism2022_english-10268   \n",
              "44    sexism2022_english-10735   \n",
              "...                        ...   \n",
              "5268  sexism2022_english-19421   \n",
              "5270  sexism2022_english-15150   \n",
              "5275   sexism2022_english-1196   \n",
              "5276   sexism2022_english-9772   \n",
              "5277  sexism2022_english-14511   \n",
              "\n",
              "                                                   text       label split  \n",
              "21    fuck the niggers and the jews. both have a his...  not sexist  test  \n",
              "27    well then good because someone has to knock he...      sexist  test  \n",
              "35    #usa #texas #islam #muslims #islamization #sha...  not sexist  test  \n",
              "38    yes, normal women want to be dominated. social...      sexist  test  \n",
              "44    she didn't have to be a bitch about it. she li...      sexist  test  \n",
              "...                                                 ...         ...   ...  \n",
              "5268             so did you break it off with her then.  not sexist  test  \n",
              "5270  in early middle school i was physically bullie...      sexist  test  \n",
              "5275  it was like a big sisterhood all stemming from...      sexist  test  \n",
              "5276  it goes like this: i'm on the dance floor and ...  not sexist  test  \n",
              "5277  it could be like for the ladies' corner of you...      sexist  test  \n",
              "\n",
              "[1086 rows x 4 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Verify test set\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b4a943b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "b4a943b0",
        "outputId": "71f8e601-abf1-4739-a830-363ad436104b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rewire_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sexism2022_english-9609</td>\n",
              "      <td>in nigeria, if you rape a woman, the men rape ...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sexism2022_english-16993</td>\n",
              "      <td>then, she's a keeper. üòâ</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sexism2022_english-13149</td>\n",
              "      <td>this is like the metallica video where the poo...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sexism2022_english-13021</td>\n",
              "      <td>woman?</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sexism2022_english-966</td>\n",
              "      <td>i bet she wished she had a gun</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5271</th>\n",
              "      <td>sexism2022_english-19863</td>\n",
              "      <td>supporting toxic men and glorifying toxic male...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5272</th>\n",
              "      <td>sexism2022_english-18722</td>\n",
              "      <td>find a girl with common beliefs. i have. they ...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5273</th>\n",
              "      <td>sexism2022_english-2564</td>\n",
              "      <td>not to mention that she's an outright commie w...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5274</th>\n",
              "      <td>sexism2022_english-4599</td>\n",
              "      <td>only if you make it clear you're not looking f...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5278</th>\n",
              "      <td>sexism2022_english-9538</td>\n",
              "      <td>yea. most trans women hate men.</td>\n",
              "      <td>sexist</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4193 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     rewire_id  \\\n",
              "0      sexism2022_english-9609   \n",
              "1     sexism2022_english-16993   \n",
              "2     sexism2022_english-13149   \n",
              "3     sexism2022_english-13021   \n",
              "4       sexism2022_english-966   \n",
              "...                        ...   \n",
              "5271  sexism2022_english-19863   \n",
              "5272  sexism2022_english-18722   \n",
              "5273   sexism2022_english-2564   \n",
              "5274   sexism2022_english-4599   \n",
              "5278   sexism2022_english-9538   \n",
              "\n",
              "                                                   text       label  split  \n",
              "0     in nigeria, if you rape a woman, the men rape ...  not sexist  train  \n",
              "1                               then, she's a keeper. üòâ  not sexist  train  \n",
              "2     this is like the metallica video where the poo...  not sexist  train  \n",
              "3                                                woman?  not sexist  train  \n",
              "4                        i bet she wished she had a gun  not sexist  train  \n",
              "...                                                 ...         ...    ...  \n",
              "5271  supporting toxic men and glorifying toxic male...      sexist  train  \n",
              "5272  find a girl with common beliefs. i have. they ...  not sexist  train  \n",
              "5273  not to mention that she's an outright commie w...  not sexist  train  \n",
              "5274  only if you make it clear you're not looking f...  not sexist  train  \n",
              "5278                    yea. most trans women hate men.      sexist  train  \n",
              "\n",
              "[4193 rows x 4 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Verify train set\n",
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bd849d8",
      "metadata": {
        "id": "6bd849d8"
      },
      "source": [
        "# 2.Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54174912",
      "metadata": {
        "id": "54174912"
      },
      "source": [
        "## Method 1: TF-IDF word n-grams (1‚Äì3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aKT0D9nZILm2",
      "metadata": {
        "id": "aKT0D9nZILm2"
      },
      "source": [
        "Our first feature method aims to build a classical machine learning representation of the text, so we chose the word n-gram feature. This approach captures local liguistic patterns, such as keywords, short phrases, and recurring expressions that could help distinguish sexist from non-sexist language."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3-DO1HZpJMnA",
      "metadata": {
        "id": "3-DO1HZpJMnA"
      },
      "source": [
        "To create our word n-gram feature method, we first wrote a helper function to generate uni-grams, bi-grams, and tri-grams after removing English stopwords to reduce noise. We applied this function to every text in the training set and counted how often each n-gram appeared in the sexist and non-sexist classes, giving us an initial understanding of which phrases characterize each category. Then, we used a TF-IDF vectorizer with ngram_range=(1,3) and min_df=2 to convert the text into numerical features. The vectorizer was fit only on the training data to avoid data leakage, and then applied to the test set using the learned vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b27bec6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b27bec6e",
        "outputId": "e99e221b-36b8-45b9-baaf-04d6b3ab4bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N-gram feature matrix created!\n",
            "Train shape: (4193, 6472)\n",
            "Test shape: (1086, 6472)\n"
          ]
        }
      ],
      "source": [
        "# Feature extraction: N-grams\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Function to generate n-grams from text, filtering stopwords\n",
        "def generate_ngrams(text, n=1):\n",
        "    # Split text and remove stopwords\n",
        "    words = [w for w in text.split() if w not in ENGLISH_STOP_WORDS]\n",
        "    # Generate n-grams\n",
        "    ngrams_list = zip(*[words[i:] for i in range(n)])\n",
        "    return [' '.join(ng) for ng in ngrams_list]\n",
        "\n",
        "# Dictionaries to store counts for sexist and non-sexist classes\n",
        "sexist_ngrams = defaultdict(int)\n",
        "nonsexist_ngrams = defaultdict(int)\n",
        "\n",
        "# Loop through training data and count n-grams\n",
        "for text, label in zip(train_df['text'], train_df['label']):\n",
        "    for n in [1, 2, 3]:\n",
        "        for ng in generate_ngrams(text, n):\n",
        "            if label == 'sexist':\n",
        "                sexist_ngrams[ng] += 1\n",
        "            else:\n",
        "                nonsexist_ngrams[ng] += 1\n",
        "\n",
        "\n",
        "#TF-IDF with n-grams 1 to 3\n",
        "ngram_vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1,3),\n",
        "    stop_words='english',\n",
        "    min_df=2\n",
        ")\n",
        "\n",
        "# Fit ONLY on training set (very important for Rule 1)\n",
        "X_train_ngrams = ngram_vectorizer.fit_transform(train_df['text'])\n",
        "\n",
        "# Transform test set using the train vocabulary\n",
        "X_test_ngrams = ngram_vectorizer.transform(test_df['text'])\n",
        "\n",
        "# Labels\n",
        "y_train = train_df['label']\n",
        "y_test = test_df['label']\n",
        "\n",
        "print(\"N-gram feature matrix created!\")\n",
        "print(\"Train shape:\", X_train_ngrams.shape)\n",
        "print(\"Test shape:\", X_test_ngrams.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c35f532f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c35f532f",
        "outputId": "99754f07-710c-439c-8c82-3e5e5350dc6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 n-grams for sexist class:\n",
            "[('women', 386), ('like', 172), ('men', 145), ('just', 141), ('woman', 92), ('bitch', 87), (\"don't\", 86), ('want', 82), (\"it's\", 79), ('female', 71)]\n",
            "\n",
            "Top 10 n-grams for non-sexist class:\n",
            "[('just', 352), ('women', 322), ('like', 314), (\"don't\", 198), (\"it's\", 167), ('woman', 145), ('girl', 141), ('want', 135), ('people', 133), (\"i'm\", 128)]\n"
          ]
        }
      ],
      "source": [
        "#Verify if the method was applied correctly\n",
        "from collections import Counter\n",
        "\n",
        "print(\"Top 10 n-grams for sexist class:\")\n",
        "print(Counter(sexist_ngrams).most_common(10))\n",
        "\n",
        "print(\"\\nTop 10 n-grams for non-sexist class:\")\n",
        "print(Counter(nonsexist_ngrams).most_common(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e13d8667",
      "metadata": {},
      "source": [
        "Nithyashree. (2021, September 13). What are N-grams and how to implement them in Python? Analytics Vidhya. https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EQoSMUvatgKP",
      "metadata": {
        "id": "EQoSMUvatgKP"
      },
      "source": [
        "## Method 2: TF-IDF character n-grams (3‚Äì5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ro35JYToI_4x",
      "metadata": {
        "id": "Ro35JYToI_4x"
      },
      "source": [
        "For our second feature method, we created a character-level TF-IDF representation to capture subword patterns such as prefixes, suffixes, repeated characters, and partial word fragments that often appear in informal or misspelled online text. Using TfidfVectorizer with analyzer=\"char\" and an n-gram range of 3‚Äì5 characters, we extracted overlapping character sequences from each text and computed their TF-IDF weights, ignoring extremely rare patterns with min_df=3. As with our word n-grams, the vectorizer was fit only on the training set to prevent data leakage and then applied to the test set using the learned character-level vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "FBKWgr28tjQ3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBKWgr28tjQ3",
        "outputId": "d60ca1ff-6cbe-4536-f57a-f82b5d84327d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Char TF-IDF feature matrix created!\n",
            "Train shape: (4193, 53684)\n",
            "Test shape: (1086, 53684)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    analyzer=\"char\",\n",
        "    ngram_range=(3, 5),\n",
        "    min_df=3  # ignore super-rare patterns\n",
        ")\n",
        "\n",
        "X_train_char = char_vectorizer.fit_transform(train_df[\"text\"])\n",
        "X_test_char  = char_vectorizer.transform(test_df[\"text\"])\n",
        "\n",
        "y_train_char = train_df[\"label\"]\n",
        "y_test_char  = test_df[\"label\"]\n",
        "\n",
        "print(\"Char TF-IDF feature matrix created!\")\n",
        "print(\"Train shape:\", X_train_char.shape)\n",
        "print(\"Test shape:\", X_test_char.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5PAIY4Pmtl8E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PAIY4Pmtl8E",
        "outputId": "5c28a3cb-c4ce-441c-9571-f2ba3e010556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 sexist-associated ngrams:\n",
            "'men'  diff=0.0077  avg_sex=0.0144  avg_non=0.0067\n",
            "'men '  diff=0.0075  avg_sex=0.0119  avg_non=0.0044\n",
            "'wom'  diff=0.0063  avg_sex=0.0123  avg_non=0.0060\n",
            "' wom'  diff=0.0061  avg_sex=0.0118  avg_non=0.0058\n",
            "'en '  diff=0.0060  avg_sex=0.0140  avg_non=0.0080\n",
            "'women'  diff=0.0060  avg_sex=0.0106  avg_non=0.0046\n",
            "'wome'  diff=0.0059  avg_sex=0.0106  avg_non=0.0046\n",
            "'omen'  diff=0.0059  avg_sex=0.0105  avg_non=0.0046\n",
            "'omen '  diff=0.0059  avg_sex=0.0093  avg_non=0.0034\n",
            "'bitch'  diff=0.0056  avg_sex=0.0057  avg_non=0.0001\n",
            "'bitc'  diff=0.0056  avg_sex=0.0057  avg_non=0.0001\n",
            "' bitc'  diff=0.0055  avg_sex=0.0056  avg_non=0.0001\n",
            "' wome'  diff=0.0055  avg_sex=0.0100  avg_non=0.0045\n",
            "'bit'  diff=0.0055  avg_sex=0.0060  avg_non=0.0005\n",
            "' bit'  diff=0.0054  avg_sex=0.0058  avg_non=0.0004\n",
            "'itch'  diff=0.0054  avg_sex=0.0058  avg_non=0.0004\n",
            "'itc'  diff=0.0053  avg_sex=0.0058  avg_non=0.0005\n",
            "' wo'  diff=0.0050  avg_sex=0.0135  avg_non=0.0085\n",
            "'tch'  diff=0.0050  avg_sex=0.0061  avg_non=0.0012\n",
            "'ome'  diff=0.0047  avg_sex=0.0118  avg_non=0.0071\n",
            "\n",
            "Top 20 non-sexist-associated ngrams:\n",
            "'his'  diff=0.0016  avg_sex=0.0051  avg_non=0.0067\n",
            "'his '  diff=0.0016  avg_sex=0.0047  avg_non=0.0063\n",
            "' je'  diff=0.0014  avg_sex=0.0006  avg_non=0.0020\n",
            "'was'  diff=0.0013  avg_sex=0.0029  avg_non=0.0042\n",
            "' pe'  diff=0.0013  avg_sex=0.0025  avg_non=0.0038\n",
            "'as '  diff=0.0013  avg_sex=0.0058  avg_non=0.0071\n",
            "'...'  diff=0.0013  avg_sex=0.0055  avg_non=0.0068\n",
            "' was'  diff=0.0012  avg_sex=0.0029  avg_non=0.0041\n",
            "' ki'  diff=0.0012  avg_sex=0.0021  avg_non=0.0033\n",
            "' this'  diff=0.0012  avg_sex=0.0036  avg_non=0.0047\n",
            "'jew'  diff=0.0012  avg_sex=0.0005  avg_non=0.0016\n",
            "' sa'  diff=0.0011  avg_sex=0.0038  avg_non=0.0049\n",
            "'eop'  diff=0.0011  avg_sex=0.0012  avg_non=0.0023\n",
            "'ople'  diff=0.0011  avg_sex=0.0012  avg_non=0.0023\n",
            "'was '  diff=0.0011  avg_sex=0.0026  avg_non=0.0038\n",
            "'peopl'  diff=0.0011  avg_sex=0.0012  avg_non=0.0023\n",
            "'peop'  diff=0.0011  avg_sex=0.0012  avg_non=0.0023\n",
            "'peo'  diff=0.0011  avg_sex=0.0012  avg_non=0.0023\n",
            "'eople'  diff=0.0011  avg_sex=0.0012  avg_non=0.0023\n",
            "'eopl'  diff=0.0011  avg_sex=0.0012  avg_non=0.0023\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "feature_names = char_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Boolean masks for each class\n",
        "sex_mask = (y_train == \"sexist\")\n",
        "nsex_mask = (y_train == \"not sexist\")\n",
        "\n",
        "# If y_train is a Series, make sure these are numpy arrays\n",
        "if hasattr(sex_mask, \"values\"):\n",
        "    sex_mask = sex_mask.values\n",
        "    nsex_mask = nsex_mask.values\n",
        "\n",
        "# Average TF-IDF per n-gram, per class\n",
        "avg_sex = X_train_char[sex_mask].mean(axis=0).A1\n",
        "avg_non = X_train_char[nsex_mask].mean(axis=0).A1\n",
        "\n",
        "# Class-specific scores (difference)\n",
        "sex_score = avg_sex - avg_non      # positive => more associated with sexist\n",
        "nonsex_score = avg_non - avg_sex   # positive => more associated with non-sexist\n",
        "\n",
        "# Top 20 sexist-associated ngrams\n",
        "top20_sex_idx = np.argsort(sex_score)[-20:]\n",
        "top20_sex_ngrams = [(feature_names[i], sex_score[i], avg_sex[i], avg_non[i])\n",
        "                    for i in reversed(top20_sex_idx)]\n",
        "\n",
        "# Top 20 non-sexist-associated ngrams\n",
        "top20_non_idx = np.argsort(nonsex_score)[-20:]\n",
        "top20_non_ngrams = [(feature_names[i], nonsex_score[i], avg_sex[i], avg_non[i])\n",
        "                    for i in reversed(top20_non_idx)]\n",
        "\n",
        "print(\"Top 20 sexist-associated ngrams:\")\n",
        "for ng, score, a_s, a_n in top20_sex_ngrams:\n",
        "    print(f\"{ng!r}  diff={score:.4f}  avg_sex={a_s:.4f}  avg_non={a_n:.4f}\")\n",
        "\n",
        "print(\"\\nTop 20 non-sexist-associated ngrams:\")\n",
        "for ng, score, a_s, a_n in top20_non_ngrams:\n",
        "    print(f\"{ng!r}  diff={score:.4f}  avg_sex={a_s:.4f}  avg_non={a_n:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e46ec5f",
      "metadata": {
        "id": "5e46ec5f"
      },
      "source": [
        "# 3. Model Selection and Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f1af430",
      "metadata": {
        "id": "7f1af430"
      },
      "source": [
        "## Model 1 - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W-ZXIS35KwhQ",
      "metadata": {
        "id": "W-ZXIS35KwhQ"
      },
      "source": [
        "For our first model, we trained a Logistic Regression classifier using both methods. Logistic Regression is a strong and interpretable baseline for text classification, and it performs well in high-dimensional sparse feature spaces like TF-IDF. We used the liblinear solver with a higher iteration limit (max_iter=5000) to ensure convergence, applied class_weight=\"balanced\" to address class imbalance, and set C=0.5 to introduce moderate regularization that prevents overfitting. After fitting the model on the training n-gram matrix, we generated predictions on the test set and evaluated performance using accuracy and a detailed classification report."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8fc8eb5",
      "metadata": {
        "id": "f8fc8eb5"
      },
      "source": [
        "## Feature Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "53603abd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53603abd",
        "outputId": "653131f2-ce86-4280-89f3-26eae64932ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7643\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  not sexist       0.87      0.80      0.83       789\n",
            "      sexist       0.56      0.67      0.61       297\n",
            "\n",
            "    accuracy                           0.76      1086\n",
            "   macro avg       0.71      0.73      0.72      1086\n",
            "weighted avg       0.78      0.76      0.77      1086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MODEL 1 ‚Äî Logistic Regression - (Method 1)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Create and train the model\n",
        "log_model = log_model = LogisticRegression(\n",
        "    max_iter=5000,\n",
        "    solver=\"liblinear\",\n",
        "    class_weight=\"balanced\",\n",
        "    C=0.5\n",
        ")\n",
        "log_model.fit(X_train_ngrams, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = log_model.predict(X_test_ngrams)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "A=classification_report(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oLA7jpoStuzZ",
      "metadata": {
        "id": "oLA7jpoStuzZ"
      },
      "source": [
        "## Feature Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4-SKnkbAtt2_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-SKnkbAtt2_",
        "outputId": "c241128e-23e3-4aaf-acde-02583977c8f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7781\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  not sexist       0.86      0.83      0.84       789\n",
            "      sexist       0.59      0.64      0.61       297\n",
            "\n",
            "    accuracy                           0.78      1086\n",
            "   macro avg       0.72      0.73      0.73      1086\n",
            "weighted avg       0.78      0.78      0.78      1086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MODEL 1 ‚Äî Logistic Regression - (Method 2)\n",
        "\n",
        "# Create and train the model\n",
        "log_model = log_model = LogisticRegression(\n",
        "    max_iter=5000,\n",
        "    solver=\"liblinear\",\n",
        "    class_weight=\"balanced\",\n",
        "    C=0.5\n",
        ")\n",
        "\n",
        "log_model.fit(X_train_char, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = log_model.predict(X_test_char)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "B=classification_report(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afaac54e",
      "metadata": {
        "id": "afaac54e"
      },
      "source": [
        "## Combinated Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lbIvUiipLNiT",
      "metadata": {
        "id": "lbIvUiipLNiT"
      },
      "source": [
        "To improve the performance, we combined both feature representation by horizontally stacking the word n-grams and the character n-grams. This hybrid approach allows the model to capture both higher-level semantic phrases and fine-grained subword patterns. We then perform the Logistic Regression on the combined model, unfortunately the result is still not reaching our target of 0.82 weighted F1. We then tried implementing two more models to improve the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d3e05aee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3e05aee",
        "outputId": "15d77165-19c3-4883-bd1a-eeb14651015a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined feature matrix created!\n",
            "Train shape: (4193, 60156)\n",
            "Test shape: (1086, 60156)\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import hstack\n",
        "\n",
        "# Combine WORD n-grams + CHAR n-grams\n",
        "X_train_combined = hstack([X_train_ngrams, X_train_char])\n",
        "X_test_combined  = hstack([X_test_ngrams, X_test_char])\n",
        "\n",
        "print(\"Combined feature matrix created!\")\n",
        "print(\"Train shape:\", X_train_combined.shape)\n",
        "print(\"Test shape:\", X_test_combined.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c024d9eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c024d9eb",
        "outputId": "bff09d7b-04db-47fb-9231-180d4aa00b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy (Combined): 0.7956\n",
            "\n",
            "Classification Report (Combined Logistic Regression):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  not sexist       0.88      0.84      0.86       789\n",
            "      sexist       0.61      0.69      0.65       297\n",
            "\n",
            "    accuracy                           0.80      1086\n",
            "   macro avg       0.74      0.76      0.75      1086\n",
            "weighted avg       0.80      0.80      0.80      1086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "log_model_combined = LogisticRegression(\n",
        "    max_iter=5000,\n",
        "    solver=\"liblinear\",\n",
        "    class_weight=\"balanced\",\n",
        "    C=0.5\n",
        ")\n",
        "\n",
        "log_model_combined.fit(X_train_combined, y_train)\n",
        "\n",
        "y_pred_combined = log_model_combined.predict(X_test_combined)\n",
        "\n",
        "print(f\"Test Accuracy (Combined): {accuracy_score(y_test, y_pred_combined):.4f}\")\n",
        "print(\"\\nClassification Report (Combined Logistic Regression):\")\n",
        "C=classification_report(y_test, y_pred_combined)\n",
        "print(classification_report(y_test, y_pred_combined))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65db0cf1",
      "metadata": {
        "id": "65db0cf1"
      },
      "source": [
        "## Model 2 - Linear SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rEJX6gQ8L9TD",
      "metadata": {
        "id": "rEJX6gQ8L9TD"
      },
      "source": [
        "For our second classical model, we trained a Linear Support Vector Machine using the same feature methods. SVMs are particularly effective for high-dimensional sparse text data because they maximize the margin between classes, often outperforming Logistic Regression when decision boundaries are tight or overlap. However, we didn't see an improvement on the weighted F1 score. We moved on the next model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "535cb5ad",
      "metadata": {
        "id": "535cb5ad"
      },
      "source": [
        "## Feature Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6560e7bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6560e7bc",
        "outputId": "84526707-99f5-4324-dc71-4cb491bd3dff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Test Accuracy: 0.7744\n",
            "\n",
            "Classification Report (SVM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  not sexist       0.83      0.87      0.85       789\n",
            "      sexist       0.60      0.52      0.56       297\n",
            "\n",
            "    accuracy                           0.77      1086\n",
            "   macro avg       0.71      0.69      0.70      1086\n",
            "weighted avg       0.77      0.77      0.77      1086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MODEL 2 ‚Äî Linear SVM - (Method 1)\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Create and train the SVM model\n",
        "svm_model = LinearSVC()\n",
        "svm_model.fit(X_train_ngrams, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_svm = svm_model.predict(X_test_ngrams)\n",
        "\n",
        "# Accuracy\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"SVM Test Accuracy: {acc_svm:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report (SVM):\")\n",
        "D=classification_report(y_test, y_pred_svm)\n",
        "print(classification_report(y_test, y_pred_svm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac114118",
      "metadata": {
        "id": "ac114118"
      },
      "source": [
        "## Feature Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4d122302",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d122302",
        "outputId": "6610876b-e0a3-4e11-8e5a-a9eea142248c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Test Accuracy (Char TF-IDF): 0.8020\n",
            "\n",
            "Classification Report (SVM - Char TF-IDF):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  not sexist       0.82      0.92      0.87       789\n",
            "      sexist       0.70      0.48      0.57       297\n",
            "\n",
            "    accuracy                           0.80      1086\n",
            "   macro avg       0.76      0.70      0.72      1086\n",
            "weighted avg       0.79      0.80      0.79      1086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MODEL 2 ‚Äî Linear SVM (Method 2)\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Create and train the SVM model\n",
        "svm_model_char = LinearSVC()\n",
        "svm_model_char.fit(X_train_char, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_svm_char = svm_model_char.predict(X_test_char)\n",
        "\n",
        "# Accuracy\n",
        "acc_svm_char = accuracy_score(y_test, y_pred_svm_char)\n",
        "print(f\"SVM Test Accuracy (Char TF-IDF): {acc_svm_char:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report (SVM - Char TF-IDF):\")\n",
        "E=classification_report(y_test, y_pred_svm_char)\n",
        "print(classification_report(y_test, y_pred_svm_char))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20f96c0f",
      "metadata": {
        "id": "20f96c0f"
      },
      "source": [
        "## Combinated Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3093ae84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3093ae84",
        "outputId": "90eee7e8-c075-4ef3-98d3-7c1a7f3eb2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Test Accuracy (Combined): 0.7781\n",
            "\n",
            "Classification Report (Combined SVM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  not sexist       0.85      0.85      0.85       789\n",
            "      sexist       0.59      0.60      0.60       297\n",
            "\n",
            "    accuracy                           0.78      1086\n",
            "   macro avg       0.72      0.72      0.72      1086\n",
            "weighted avg       0.78      0.78      0.78      1086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm_combined = LinearSVC(class_weight=\"balanced\")\n",
        "svm_combined.fit(X_train_combined, y_train)\n",
        "\n",
        "y_pred_svm_comb = svm_combined.predict(X_test_combined)\n",
        "\n",
        "print(f\"SVM Test Accuracy (Combined): {accuracy_score(y_test, y_pred_svm_comb):.4f}\")\n",
        "print(\"\\nClassification Report (Combined SVM):\")\n",
        "F=classification_report(y_test, y_pred_svm_comb)\n",
        "print(classification_report(y_test, y_pred_svm_comb))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4446c23",
      "metadata": {
        "id": "c4446c23"
      },
      "source": [
        "## Model 3 - XGBOOST"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lNCrw-6aMb9u",
      "metadata": {
        "id": "lNCrw-6aMb9u"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "B0qKa88yMkE_",
      "metadata": {
        "id": "B0qKa88yMkE_"
      },
      "source": [
        "For our last classical model, we experimented with XGBoost, which is a powerful graident-boosted tree algorithm. Even though XGBoost is traditionally used for dense, low-dimensional tabular data, we adapted it to our high-dimensional sparse TF-IDF matrix by tuning parameters such as n_estimators=400, learning_rate=0.07, and mex_depth=6. We also used the hist tree method for faster training on large feature spaces. We ended up getting the highest weighted f1 score of 0.81, still not what we wanted. So the the next step we tried a deep learning method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "420bf10c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "420bf10c",
        "outputId": "bb1d9d57-9433-4c80-e5d0-6cd2b57ea8ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label encoding completed: ['not sexist' 'sexist']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Create a LabelEncoder instance to convert string labels into numeric values\n",
        "le = LabelEncoder()\n",
        "\n",
        "\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.transform(y_test)\n",
        "\n",
        "print(\"Label encoding completed:\", le.classes_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb331851",
      "metadata": {
        "id": "cb331851"
      },
      "source": [
        "## Feature Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc26b661",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc26b661",
        "outputId": "003355e2-b354-4629-d6f3-bfae1cbefb90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== XGBOOST (METHOD 1 ‚Äî WORD TF-IDF) =====\n",
            "Accuracy: 0.8130755064456722\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.88       789\n",
            "           1       0.72      0.52      0.60       297\n",
            "\n",
            "    accuracy                           0.81      1086\n",
            "   macro avg       0.78      0.72      0.74      1086\n",
            "weighted avg       0.80      0.81      0.80      1086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Initialize an XGBoost classifier with tuned hyperparameters - (Method 1)\n",
        "xgb_model_1 = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.07,\n",
        "    max_depth=6,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    eval_metric='logloss',\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "# Train the model using the TF-IDF n-gram features\n",
        "xgb_model_1.fit(X_train_ngrams, y_train_enc)\n",
        "\n",
        "# Predict the label of each test sample\n",
        "y_pred_xgb_1 = xgb_model_1.predict(X_test_ngrams)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n===== XGBOOST (METHOD 1 ‚Äî WORD TF-IDF) =====\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_enc, y_pred_xgb_1))\n",
        "print(\"\\nClassification Report:\")\n",
        "G=classification_report(y_test_enc, y_pred_xgb_1)\n",
        "print(classification_report(y_test_enc, y_pred_xgb_1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e13cc2",
      "metadata": {
        "id": "76e13cc2"
      },
      "source": [
        "## Feature Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d1bc0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34d1bc0c",
        "outputId": "df8a5c30-ebec-4996-c8cf-94fa8fa58814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== XGBOOST (METHOD 2 ‚Äî CHAR TF-IDF) =====\n",
            "Accuracy: 0.8195211786372008\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88       789\n",
            "           1       0.76      0.50      0.60       297\n",
            "\n",
            "    accuracy                           0.82      1086\n",
            "   macro avg       0.79      0.72      0.74      1086\n",
            "weighted avg       0.81      0.82      0.81      1086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize an XGBoost classifier with tuned hyperparameters - (Method 2)\n",
        "xgb_model_2 = XGBClassifier(\n",
        "    n_estimators=850,\n",
        "    learning_rate=0.02,\n",
        "    max_depth=6,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    eval_metric='logloss',\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "# Train the model using the character-level TF-IDF features\n",
        "xgb_model_2.fit(X_train_char, y_train_enc)\n",
        "\n",
        "# Predict the label of each test sample\n",
        "y_pred_xgb_2 = xgb_model_2.predict(X_test_char)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n===== XGBOOST (METHOD 2 ‚Äî CHAR TF-IDF) =====\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_enc, y_pred_xgb_2))\n",
        "print(\"\\nClassification Report:\")\n",
        "H=classification_report(y_test_enc, y_pred_xgb_2)\n",
        "print(classification_report(y_test_enc, y_pred_xgb_2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3b8ca15",
      "metadata": {
        "id": "b3b8ca15"
      },
      "source": [
        "## Combinated Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecdbb701",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "ecdbb701",
        "outputId": "dcece047-f12a-4729-934d-0690a735f7b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined feature matrix created!\n",
            "Train shape: (4193, 60156)\n",
            "Test shape: (1086, 60156)\n",
            "\n",
            "===== XGBOOST (COMBINED MODEL) =====\n",
            "Accuracy: 0.8222836095764272\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.89       789\n",
            "           1       0.77      0.51      0.61       297\n",
            "\n",
            "    accuracy                           0.82      1086\n",
            "   macro avg       0.80      0.72      0.75      1086\n",
            "weighted avg       0.82      0.82      0.81      1086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import hstack\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Combine WORD n-grams + CHAR n-grams\n",
        "X_train_combined = hstack([X_train_ngrams, X_train_char])\n",
        "X_test_combined = hstack([X_test_ngrams, X_test_char])\n",
        "\n",
        "print(\"Combined feature matrix created!\")\n",
        "print(\"Train shape:\", X_train_combined.shape)\n",
        "print(\"Test shape:\", X_test_combined.shape)\n",
        "\n",
        "# Initialize an XGBoost classifier with tuned hyperparameters - (Combined method)\n",
        "xgb_model_3 = XGBClassifier(\n",
        "    n_estimators=850,\n",
        "    learning_rate=0.02,\n",
        "    max_depth=7,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    eval_metric='logloss',\n",
        "    tree_method='hist',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train XGBoost using the combined features\n",
        "xgb_model_3.fit(X_train_combined, y_train_enc)\n",
        "\n",
        "# Predict the label of each test sample\n",
        "y_pred_xgb_3 = xgb_model_3.predict(X_test_combined)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n===== XGBOOST (COMBINED MODEL) =====\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_enc, y_pred_xgb_3))\n",
        "print(\"\\nClassification Report:\")\n",
        "I=classification_report(y_test_enc, y_pred_xgb_3)\n",
        "print(classification_report(y_test_enc, y_pred_xgb_3))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
